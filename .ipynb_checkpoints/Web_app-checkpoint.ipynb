{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9f905d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Restarting with watchdog (windowsapi)\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\conja\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3377: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "from flask import Flask, render_template, request\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing \n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.use('agg')\n",
    "from io import BytesIO\n",
    "import base64\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load and preprocess your data\n",
    "data_pt1 = pd.read_csv('Team_Analytics_Data_pt1.csv')\n",
    "data_pt1 = data_pt1.dropna()\n",
    "data_pt2 = pd.read_csv('Team_Analytics_Data_pt2.csv')\n",
    "data_pt2 = data_pt2.dropna()\n",
    "merged_df = pd.merge(data_pt1, data_pt2, on='Game_Key', how='inner')\n",
    "columns_to_keep = ['NPIE_A', 'PM_A', 'NDOFF_A', 'NSFF_A', 'SEASON_YEAR_A_x']\n",
    "data = merged_df[columns_to_keep]\n",
    "\n",
    "validation = data[data['SEASON_YEAR_A_x'] == '2022-23']\n",
    "modelData = data[data['SEASON_YEAR_A_x'] != '2022-23'].sample(frac=1)\n",
    "X = modelData.drop(columns=['PM_A', 'SEASON_YEAR_A_x'], axis=1)\n",
    "y = modelData['PM_A']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.33)\n",
    "\n",
    "# Standard Scaling Prediction Variables\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "scaled_data_train = scaler.transform(X_train)\n",
    "\n",
    "scaler.fit(X_test)\n",
    "scaled_data_test = scaler.transform(X_test)\n",
    "# Standard Scaling Prediction Variables\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(validation.drop(['PM_A','SEASON_YEAR_A_x'],axis=1))\n",
    "scaled_val_data = scaler.transform(validation.drop(['PM_A','SEASON_YEAR_A_x'],axis=1))\n",
    "y_valid = validation['PM_A']\n",
    "\n",
    "# Create your machine learning models and preprocessors here\n",
    "random.seed(420)\n",
    "rfr = RandomForestRegressor()\n",
    "rfr.fit(scaled_data_train,y_train)\n",
    "lr = LinearRegression()\n",
    "lr.fit(scaled_data_train,y_train)\n",
    "knnNorm = KNeighborsRegressor(n_neighbors= 10)\n",
    "knnNorm.fit(scaled_data_train, y_train)\n",
    "gbr = GradientBoostingRegressor()\n",
    "gbr.fit(scaled_data_train,y_train)\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route('/simulate', methods=['GET'])\n",
    "def simulate():\n",
    "    return render_template('simulate.html')\n",
    "    \n",
    "    \n",
    "\n",
    "@app.route('/simulation_result', methods=['POST'])\n",
    "def simulation_result():\n",
    "    if request.method == 'POST':\n",
    "        # Get user input for team abbreviations and H_A\n",
    "        team_abbreviation_a = request.form['team_abbreviation_a']\n",
    "        team_abbreviation_b = request.form['team_abbreviation_b']\n",
    "        h_a = 1\n",
    "\n",
    "        # Apply filters to the DataFrame\n",
    "        filtered_df = merged_df[\n",
    "            (merged_df['TEAM_ABBREVIATION_A_x'] == team_abbreviation_a) &\n",
    "            (merged_df['TEAM_ABBREVIATION_B_x'] == team_abbreviation_b) &\n",
    "            (merged_df['H_A'] == h_a)\n",
    "        ]\n",
    "\n",
    "        # Convert the date columns to datetime objects\n",
    "        filtered_df['GAME_DATE_A_x'] = pd.to_datetime(filtered_df['GAME_DATE_A_x'])\n",
    "\n",
    "        # Sort the filtered DataFrame by game_date in descending order\n",
    "        filtered_df = filtered_df.sort_values(by='GAME_DATE_A_x', ascending=False)\n",
    "\n",
    "        # Calculate the decay factor based on the time elapsed since the latest game_date\n",
    "        latest_game_date = filtered_df['GAME_DATE_A_x'].max()\n",
    "        filtered_df['decay_factor'] = np.exp(-0.001 * (latest_game_date - filtered_df['GAME_DATE_A_x']).dt.days)\n",
    "\n",
    "        # Calculate weighted averages using the decay factor\n",
    "        average_npie_a = (filtered_df['NPIE_A'] * filtered_df['decay_factor']).sum() / filtered_df['decay_factor'].sum()\n",
    "        average_ndoff_a = (filtered_df['NDOFF_A'] * filtered_df['decay_factor']).sum() / filtered_df['decay_factor'].sum()\n",
    "        average_nsff_a = (filtered_df['NSFF_A'] * filtered_df['decay_factor']).sum() / filtered_df['decay_factor'].sum()\n",
    "\n",
    "        # Calculate weighted standard deviations using the decay factor\n",
    "        std_dev_npie_a = np.sqrt(\n",
    "            ((filtered_df['NPIE_A'] - average_npie_a)**2 * filtered_df['decay_factor']).sum()\n",
    "            / filtered_df['decay_factor'].sum()\n",
    "        )\n",
    "        std_dev_ndoff_a = np.sqrt(\n",
    "            ((filtered_df['NDOFF_A'] - average_ndoff_a)**2 * filtered_df['decay_factor']).sum()\n",
    "            / filtered_df['decay_factor'].sum()\n",
    "        )\n",
    "        std_dev_nsff_a = np.sqrt(\n",
    "            ((filtered_df['NSFF_A'] - average_nsff_a)**2 * filtered_df['decay_factor']).sum()\n",
    "            / filtered_df['decay_factor'].sum()\n",
    "        )\n",
    "        \n",
    "        # Simulate using the user-provided values\n",
    "        num_samples = 10000\n",
    "        samples_1 = np.random.normal(average_npie_a, std_dev_npie_a, num_samples)\n",
    "        samples_2 = np.random.normal(average_ndoff_a, std_dev_ndoff_a, num_samples)\n",
    "        samples_3 = np.random.normal(average_nsff_a, std_dev_nsff_a, num_samples)\n",
    "\n",
    "        # Create a pandas DataFrame using the simulated samples\n",
    "        data_simulated = {\n",
    "            'NPIE_A': samples_1,\n",
    "            'NDOFF_A': samples_2,\n",
    "            'NSFF_A': samples_3\n",
    "        }\n",
    "\n",
    "        df_simulated = pd.DataFrame(data_simulated, columns=['NPIE_A', 'NDOFF_A', 'NSFF_A'])\n",
    "\n",
    "        # Apply any necessary preprocessing on df_simulated here\n",
    "        scaled_MyGameSim = scaler.transform(df_simulated)\n",
    "        # ...\n",
    "\n",
    "        # Use your machine learning models for prediction\n",
    "        rfr_predicted_sim = rfr.predict(scaled_MyGameSim)\n",
    "        lr_predicted_sim = lr.predict(scaled_MyGameSim)\n",
    "        knnNorm_predicted_sim = knnNorm.predict(scaled_MyGameSim)\n",
    "        gbr_predicted_sim = gbr.predict(scaled_MyGameSim)\n",
    "        average_predictions = (rfr_predicted_sim + lr_predicted_sim + knnNorm_predicted_sim + gbr_predicted_sim) / 4\n",
    "\n",
    "        #Histogram creation output:\n",
    "        num_samples = 100\n",
    "\n",
    "        # Calculate mean of the average predictions\n",
    "        mean_average = np.mean(average_predictions)\n",
    "        std_average = np.std(average_predictions)\n",
    "\n",
    "        # Create an array to store bootstrapped sample means\n",
    "        bootstrapped_means = np.zeros(num_samples)\n",
    "\n",
    "        # Perform bootstrapping\n",
    "        for i in range(num_samples):\n",
    "            # Randomly sample indices with replacement\n",
    "            bootstrap_indices = np.random.choice(len(average_predictions), size=len(average_predictions), replace=True)\n",
    "\n",
    "            # Use the sampled indices to create a bootstrap sample\n",
    "            bootstrap_sample = average_predictions[bootstrap_indices]\n",
    "\n",
    "            # Calculate the mean of the bootstrap sample\n",
    "            bootstrapped_means[i] = np.mean(bootstrap_sample)\n",
    "\n",
    "        # Calculate the 95% confidence interval\n",
    "        confidence_interval = np.percentile(bootstrapped_means, [2.5, 97.5])\n",
    "\n",
    "        # Print the mean and confidence interval\n",
    "        print(f\"Mean Average: {mean_average}\")\n",
    "        print(f\"Standard Deviation: {std_average}\")\n",
    "        print(f\"95% Confidence Interval: {confidence_interval}\")\n",
    "\n",
    "\n",
    "        # Create a figure and axis with a larger figure size\n",
    "        plt.figure(figsize=(10, 6))\n",
    "\n",
    "        # Create a histogram of the average predictions with enhanced visuals\n",
    "        plt.hist(bootstrapped_means, bins=20, color='skyblue', edgecolor='gray', alpha=0.7)\n",
    "\n",
    "        # Add vertical lines for mean and confidence intervals with labels\n",
    "        plt.axvline(x=mean_average, color='red', linestyle='dashed', linewidth=2, label='Mean')\n",
    "        \n",
    "        # Add labels and legend\n",
    "        plt.xlabel('Average Plus Minus Predictions')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.title('Histogram of Plus Minus Bootstrap')\n",
    "        plt.legend()\n",
    "\n",
    "        # Add a grid for better readability\n",
    "        plt.grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "        # Adjust layout to prevent label cutoff and overlap\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Save the plot as a BytesIO object and encode it to base64\n",
    "        img_stream = BytesIO()\n",
    "        plt.savefig(img_stream, format='png')\n",
    "        img_stream.seek(0)\n",
    "        img_base64_1 = base64.b64encode(img_stream.read()).decode('utf-8')\n",
    "        plt.close()\n",
    "        \n",
    "        # Create the second histogram with enhanced visuals (replace this with your code)\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        \n",
    "        # Calculate mean and 25% confidence interval of the average predictions\n",
    "        mean_average = np.mean(average_predictions)\n",
    "        std_average = np.std(average_predictions)\n",
    "        confidence_interval = np.percentile(average_predictions, [37.5, 62.5])  # 25% confidence interval\n",
    "\n",
    "        # Print the values of the 25% confidence interval\n",
    "        print(f\"Mean Average: {mean_average}\")\n",
    "        print(f\"Standard Deviation: {std_average}\")\n",
    "        print(f\"Lower Bound of 25% Confidence Interval: {confidence_interval[0]}\")\n",
    "        print(f\"Upper Bound of 25% Confidence Interval: {confidence_interval[1]}\")\n",
    "\n",
    "        # Create a histogram of the average predictions\n",
    "        plt.hist(average_predictions, bins=20, color='blue', alpha=0.7)\n",
    "\n",
    "        # Add mean and 70% confidence interval lines to the histogram\n",
    "        plt.axvline(x=mean_average, color='red', linestyle='dashed', linewidth=2, label='Mean')\n",
    "        plt.axvline(x=confidence_interval[0], color='green', linestyle='dashed', linewidth=2, label='25% Confidence Interval')\n",
    "        plt.axvline(x=confidence_interval[1], color='green', linestyle='dashed', linewidth=2)\n",
    "\n",
    "        # Add labels and legend\n",
    "        plt.xlabel('Plus Minus')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.title('Histogram of Plus Minus')\n",
    "        plt.legend()\n",
    "        \n",
    "        # Add a grid for better readability\n",
    "        plt.grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "        # Adjust layout to prevent label cutoff and overlap\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Save the plot as a BytesIO object and encode it to base64\n",
    "        img_stream = BytesIO()\n",
    "        plt.savefig(img_stream, format='png')\n",
    "        img_stream.seek(0)\n",
    "        img_base64_2 = base64.b64encode(img_stream.read()).decode('utf-8')\n",
    "        plt.close()\n",
    "        \n",
    "        # Create histogram 3 with enhanced visuals (replace this with your code)\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        \n",
    "        # Calculate the proportion of values greater than 1\n",
    "        boolean_array = average_predictions > 1\n",
    "        proportion_greater_than_1 = np.mean(boolean_array)\n",
    "        # Convert boolean array to numbers (0s and 1s)\n",
    "        boolean_array = boolean_array.astype(int)\n",
    "\n",
    "        # Create a figure and axis with a larger figure size\n",
    "        plt.figure(figsize=(10, 6))\n",
    "\n",
    "        # Create a histogram of the proportion values with enhanced visuals\n",
    "        plt.hist(boolean_array,  bins=[ -0.3, 0.3, 0.7, 1.3], color='blue', alpha=0.7,edgecolor='black')\n",
    "\n",
    "        # Add mean line to the histogram\n",
    "        plt.axvline(x=proportion_greater_than_1, color='red', linestyle='dashed', linewidth=2, label='Mean')\n",
    "        plt.xticks([0, 0.5, 1], ['0', '0.5', '1'])\n",
    "        # Add labels and legend\n",
    "        plt.xlabel('Win Loss')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.title('Win Loss Histogram')\n",
    "        plt.legend()\n",
    "    \n",
    "        # Print the mean and confidence interval values\n",
    "        print(f\"Mean Proportion: {proportion_greater_than_1}\")\n",
    "        \n",
    "        # Add a grid for better readability\n",
    "        plt.grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "        # Adjust layout to prevent label cutoff and overlap\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Save the plot as a BytesIO object and encode it to base64\n",
    "        img_stream = BytesIO()\n",
    "        plt.savefig(img_stream, format='png')\n",
    "        img_stream.seek(0)\n",
    "        img_base64_3 = base64.b64encode(img_stream.read()).decode('utf-8')\n",
    "        plt.close()\n",
    "\n",
    "        # Return a response to the user\n",
    "        return render_template('simulation_result.html', result=np.mean(average_predictions), win_chance=np.mean(average_predictions>1),img_data_1=img_base64_1, img_data_2=img_base64_2, img_data_3=img_base64_3,\n",
    "                           mean_average=mean_average, std_average=std_average,\n",
    "                           confidence_interval=confidence_interval,proportion_greater_than_1=proportion_greater_than_1 \n",
    "                           )\n",
    "\n",
    "    return \"Invalid request\"\n",
    "\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fd5c3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
